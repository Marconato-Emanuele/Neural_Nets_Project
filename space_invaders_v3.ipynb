{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDUuD7YFnx4s"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import imageio\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQzPxj0MpyWg"
   },
   "outputs": [],
   "source": [
    "STORE_PATH = 'Projetto_Reti2020'\n",
    "MAX_EPSILON = 0.9\n",
    "MIN_EPSILON = 0.1\n",
    "EPSILON_MIN_ITER = 100000\n",
    "GAMMA = 0.99 #discount factor \n",
    "BATCH_SIZE = 32\n",
    "TAU = 0.08 \n",
    "DELAY_TRAINING = 25000 \n",
    "NUM_FRAMES = 4 #stacked frames to train the network\n",
    "GIF_RECORDING_FREQ = 100\n",
    "\n",
    "env = gym.make(\"SpaceInvaders-v0\")\n",
    "num_actions = env.action_space.n\n",
    "space_dim   = env.observation_space.shape\n",
    "\n",
    "POST_PROCESS_IMAGE_SIZE = (105, 80, 4) #resize the image from (210,160) to (105,80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VNdWr2TZqXkh"
   },
   "source": [
    "Definition of the model:\n",
    "* 3 convolutional layers (to extract relevant features)\n",
    "* 1 flatten (mute reshaping layer)\n",
    "* 1 fully-connected layer \n",
    "* 1 output layer with n=num_actions units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shaVe-T9xEFs"
   },
   "outputs": [],
   "source": [
    "def CNN(input_shape=(105,80,4), output_layer= 3, last_activation = None):\n",
    "    model = keras.Sequential(\n",
    "      [keras.Input(shape=input_shape, name=\"input_layer\" ),\n",
    "       layers.Conv2D( filters=16, kernel_size= 8,strides=4, padding=\"valid\", activation = \"relu\" ),\n",
    "       layers.Conv2D( filters=32, kernel_size= 4,strides=2, padding=\"valid\", activation = \"relu\" ),\n",
    "       layers.Conv2D( filters= 32, kernel_size= 3,strides=1, padding=\"valid\", activation = \"relu\" )             \n",
    "      ]\n",
    "    ) \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(units= output_layer, activation = last_activation))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9H5m25mXqiDh"
   },
   "source": [
    "Network initialization. \\\n",
    "Note: target network is set as a copy of primary network.\\\n",
    "OPTIMIZER = Adam with loss mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVovX1rStX-x"
   },
   "outputs": [],
   "source": [
    "primary_network = CNN(input_shape= POST_PROCESS_IMAGE_SIZE, output_layer=num_actions)\n",
    "target_network  = CNN(input_shape= POST_PROCESS_IMAGE_SIZE, output_layer= num_actions)\n",
    "primary_network.compile(optimizer=keras.optimizers.Adam(), loss='mse')\n",
    "# make target_network = primary_network\n",
    "for t, e in zip(target_network.trainable_variables, primary_network.trainable_variables):\n",
    "    t.assign(e)\n",
    "\n",
    "primary_network.compile(optimizer=keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "NZHhumgPxTuE",
    "outputId": "7935fe6e-741f-4e34-abe5-76131ec2e72c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 25, 19, 16)        4112      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 8, 32)         8224      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 9, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 243,670\n",
      "Trainable params: 243,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "primary_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8q1RrhZHqozM"
   },
   "source": [
    "Memory class buffer, with add_sample to store transitions and sample to extract a batch of BATCH_SIZE dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9sitNfMgqldY"
   },
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, max_memory):\n",
    "        self._max_memory = max_memory\n",
    "        self._actions = np.zeros(max_memory, dtype=np.int32)\n",
    "        self._rewards = np.zeros(max_memory, dtype=np.float32)\n",
    "        self._frames = np.zeros((POST_PROCESS_IMAGE_SIZE[0], POST_PROCESS_IMAGE_SIZE[1], max_memory), dtype=np.float32)\n",
    "        self._terminal = np.zeros(max_memory, dtype=np.bool)\n",
    "        self._i = 0\n",
    "\n",
    "    def add_sample(self, frame, action, reward, terminal):\n",
    "        self._actions[self._i] = action\n",
    "        self._rewards[self._i] = reward\n",
    "        self._frames[:, :, self._i] = frame[:, :, 0]\n",
    "        self._terminal[self._i] = terminal\n",
    "        if self._i % (self._max_memory - 1) == 0 and self._i != 0:\n",
    "            self._i = BATCH_SIZE + NUM_FRAMES + 1\n",
    "        else:\n",
    "            self._i += 1\n",
    "\n",
    "    def sample(self):\n",
    "        if self._i < BATCH_SIZE + NUM_FRAMES + 1:\n",
    "            raise ValueError(\"Not enough memory to extract a batch\")\n",
    "        else:\n",
    "            rand_idxs = np.random.randint(NUM_FRAMES + 1, self._i, size=BATCH_SIZE)\n",
    "            states = np.zeros((BATCH_SIZE, POST_PROCESS_IMAGE_SIZE[0], POST_PROCESS_IMAGE_SIZE[1], NUM_FRAMES),\n",
    "                             dtype=np.float32)\n",
    "            next_states = np.zeros((BATCH_SIZE, POST_PROCESS_IMAGE_SIZE[0], POST_PROCESS_IMAGE_SIZE[1], NUM_FRAMES),\n",
    "                             dtype=np.float32)\n",
    "            for i, idx in enumerate(rand_idxs):\n",
    "                states[i] = self._frames[:, :, idx - 1 - NUM_FRAMES:idx - 1]\n",
    "                next_states[i] = self._frames[:, :, idx - NUM_FRAMES:idx]\n",
    "            return states, self._actions[rand_idxs], self._rewards[rand_idxs], next_states, self._terminal[rand_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UTnaHEa9qzd_"
   },
   "outputs": [],
   "source": [
    "#start memory as large as possible (based on aviable RAM) to store more episodes\n",
    "memory = Memory(150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rb9XVfF9q-us"
   },
   "source": [
    "Some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYRoaQJEq5xC"
   },
   "outputs": [],
   "source": [
    "def image_preprocess(image, new_size=(105,80)):\n",
    "    # convert to greyscale, resize and normalize the image\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image, new_size)\n",
    "    image = image / 255\n",
    "    return image\n",
    "\n",
    "\n",
    "def choose_action(state, primary_network, eps, step):\n",
    "  #eps-greedy action after DELAY_TRAINING\n",
    "    if step < DELAY_TRAINING:\n",
    "        return random.randint(0, num_actions - 1)\n",
    "    else:\n",
    "        if random.random() < eps:\n",
    "            return random.randint(0, num_actions - 1)\n",
    "        else:\n",
    "            return np.argmax(primary_network(tf.reshape(state, (1, POST_PROCESS_IMAGE_SIZE[0],\n",
    "                                                           POST_PROCESS_IMAGE_SIZE[1], NUM_FRAMES)).numpy()))\n",
    "\n",
    "\n",
    "def update_network(primary_network, target_network, check= False):\n",
    "    # update target network parameters slowly from primary network\n",
    "    #completely after T episodes\n",
    "    if check:\n",
    "        tau = 1\n",
    "    else: tau = 0.08\n",
    "    for t, e in zip(target_network.trainable_variables, primary_network.trainable_variables):\n",
    "        t.assign(t * (1 - tau) + e * tau)\n",
    "\n",
    "\n",
    "def process_state_stack(state_stack, state):\n",
    "  #images stack\n",
    "    for i in range(1, state_stack.shape[-1]):\n",
    "        state_stack[:, :, i - 1].assign(state_stack[:, :, i])\n",
    "    state_stack[:, :, -1].assign(state[:, :, 0])\n",
    "    return state_stack\n",
    "\n",
    "\n",
    "def record_gif(frame_list, episode, fps=50):\n",
    "    imageio.mimsave(STORE_PATH + f\"/SpaceInvaders_EPISODE-{episode}.gif\", frame_list, fps=fps) #duration=duration_per_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLDcUFPurGV4"
   },
   "source": [
    "Training structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSq-cjSXrB-n"
   },
   "outputs": [],
   "source": [
    "def train(primary_network, memory, target_network=None):\n",
    "    #Train function based on DQN with single step\n",
    "    states, actions, rewards, next_states, terminal = memory.sample()\n",
    "    # predict Q(s,a) given the batch of states\n",
    "    prim_qt = primary_network(states)\n",
    "    # predict Q(s',a') from the evaluation network\n",
    "    prim_qtp1 = primary_network(next_states)\n",
    "    # copy the prim_qt tensor into the target_q tensor - we then will update one index corresponding to the max action\n",
    "    target_q = prim_qt.numpy()\n",
    "    updates = rewards\n",
    "    valid_idxs = terminal != True\n",
    "    batch_idxs = np.arange(BATCH_SIZE)\n",
    "    if target_network is None:\n",
    "        updates[valid_idxs] += GAMMA * np.amax(prim_qtp1.numpy()[valid_idxs, :], axis=1) #never used this\n",
    "    else:\n",
    "        prim_action_tp1 = np.argmax(prim_qtp1.numpy(), axis=1)\n",
    "        q_from_target = target_network(next_states)\n",
    "        updates[valid_idxs] += GAMMA * q_from_target.numpy()[batch_idxs[valid_idxs], prim_action_tp1[valid_idxs]]\n",
    "    target_q[batch_idxs, actions] = updates\n",
    "    loss = primary_network.train_on_batch(states, target_q)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOK271ha-U1b"
   },
   "source": [
    "GPU initialization in COLAB. This is not necessary if the compiler has no GPU. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P_jB4Ozmsq2b",
    "outputId": "b20c5214-eddb-4521-bb0b-08a99620268c"
   },
   "outputs": [],
   "source": [
    "#device_name = tf.test.gpu_device_name()\n",
    "#if device_name != '/device:GPU:0':\n",
    "#    raise SystemError('GPU device not found')\n",
    "#print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHEE56tUsyWA"
   },
   "outputs": [],
   "source": [
    "#set how many records are necessary before to start batch-sampling from the memory class \n",
    "DELAY_TRAINING = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "McUACNyXrKRC",
    "outputId": "13cc4b8c-e5dd-46bd-b561-69908abff265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training...Episode: 0\n",
      "Pre-training...Episode: 1\n",
      "Pre-training...Episode: 2\n",
      "Pre-training...Episode: 3\n",
      "Pre-training...Episode: 4\n",
      "Pre-training...Episode: 5\n",
      "Pre-training...Episode: 6\n",
      "Pre-training...Episode: 7\n",
      "Pre-training...Episode: 8\n",
      "Pre-training...Episode: 9\n",
      "Pre-training...Episode: 10\n",
      "Pre-training...Episode: 11\n",
      "Pre-training...Episode: 12\n",
      "Pre-training...Episode: 13\n",
      "Pre-training...Episode: 14\n",
      "Pre-training...Episode: 15\n",
      "Pre-training...Episode: 16\n",
      "Pre-training...Episode: 17\n",
      "Pre-training...Episode: 18\n",
      "Pre-training...Episode: 19\n",
      "Pre-training...Episode: 20\n",
      "Pre-training...Episode: 21\n",
      "Pre-training...Episode: 22\n",
      "Pre-training...Episode: 23\n",
      "Pre-training...Episode: 24\n",
      "Pre-training...Episode: 25\n",
      "Pre-training...Episode: 26\n",
      "Pre-training...Episode: 27\n",
      "Pre-training...Episode: 28\n",
      "Pre-training...Episode: 29\n",
      "Pre-training...Episode: 30\n",
      "Pre-training...Episode: 31\n",
      "Pre-training...Episode: 32\n",
      "Pre-training...Episode: 33\n",
      "Pre-training...Episode: 34\n",
      "Pre-training...Episode: 35\n",
      "Pre-training...Episode: 36\n",
      "Episode: 37, Reward: 30.0, avg loss: -0.01918, eps: 0.897, Time:  72\n",
      "Episode: 38, Reward: 210.0, avg loss: 0.03620, eps: 0.891, Time:  148\n",
      "Episode: 39, Reward: 135.0, avg loss: 0.03398, eps: 0.886, Time:  111\n",
      "Episode: 40, Reward: 210.0, avg loss: 0.03385, eps: 0.879, Time:  158\n",
      "Episode: 41, Reward: 240.0, avg loss: 0.03568, eps: 0.872, Time:  154\n",
      "Episode: 42, Reward: 105.0, avg loss: 0.03630, eps: 0.866, Time:  129\n",
      "Episode: 43, Reward: 150.0, avg loss: 0.03874, eps: 0.858, Time:  167\n",
      "Episode: 44, Reward: 265.0, avg loss: 0.03630, eps: 0.851, Time:  166\n",
      "Episode: 45, Reward: 150.0, avg loss: 0.03281, eps: 0.845, Time:  110\n",
      "Episode: 46, Reward: 110.0, avg loss: 0.03478, eps: 0.840, Time:  112\n",
      "Episode: 47, Reward: 45.0, avg loss: 0.03293, eps: 0.835, Time:  97\n",
      "Episode: 48, Reward: 135.0, avg loss: 0.04202, eps: 0.831, Time:  85\n",
      "Episode: 49, Reward: 110.0, avg loss: 0.03369, eps: 0.826, Time:  97\n",
      "Episode: 50, Reward: 135.0, avg loss: 0.03479, eps: 0.821, Time:  115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ff65b1fb0df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mDELAY_TRAINING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mupdate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-7f6afe2266e6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(primary_network, memory, target_network)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mupdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idxs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq_from_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprim_action_tp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtarget_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimary_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                                     class_weight)\n\u001b[1;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#device_name = tf.test.gpu_device_name()\n",
    "#if device_name != '/device:GPU:0':\n",
    "#    print(\n",
    "#      '\\n\\nThis error most likely means that this notebook is not '\n",
    "#      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "#      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "#    raise SystemError('GPU device not found')\n",
    "#with tf.device('/device:GPU:0'):\n",
    "if True:\n",
    "    num_episodes = 10000 #note that they should be even more\n",
    "    eps = MAX_EPSILON\n",
    "    render = False #passing render if you want to render the game during training\n",
    "    train_writer = tf.summary.create_file_writer(STORE_PATH + f\"/DQN_{dt.datetime.now().strftime('%d%m%Y%H%M')}\")\n",
    "\n",
    "    steps = 0\n",
    "    ep_time = current_milli_time()\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        state = image_preprocess(state)\n",
    "        state_stack = tf.Variable(np.repeat(state.numpy(), NUM_FRAMES).reshape((POST_PROCESS_IMAGE_SIZE[0],\n",
    "                                                                                  POST_PROCESS_IMAGE_SIZE[1],\n",
    "                                                                                  NUM_FRAMES)))\n",
    "        cnt = 1\n",
    "        avg_loss = 0\n",
    "        tot_reward = 0\n",
    "        if i % GIF_RECORDING_FREQ == 0:\n",
    "            frame_list = []\n",
    "        while True:\n",
    "          #if render:\n",
    "          #    env.render()\n",
    "            #eps-greedy action\n",
    "            action = choose_action(state_stack, primary_network, eps, steps)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            tot_reward += reward\n",
    "            if i % GIF_RECORDING_FREQ == 0:\n",
    "                frame_list.append(tf.cast(tf.image.resize(next_state, (480, 320)), tf.uint8).numpy())\n",
    "            next_state = image_preprocess(next_state)\n",
    "            state_stack = process_state_stack(state_stack, next_state)\n",
    "          # store in memory\n",
    "            memory.add_sample(next_state, action, reward, done)\n",
    "\n",
    "            if steps > DELAY_TRAINING:\n",
    "                loss = train(primary_network, memory, target_network)\n",
    "                if i < 100:\n",
    "                    update_network(primary_network, target_network, check= False)\n",
    "                else:\n",
    "                    if i % 100 == 0:\n",
    "                        update_network(primary_network,target_network,check=True)\n",
    "\n",
    "            else:\n",
    "                loss = -1\n",
    "            avg_loss += loss\n",
    "\n",
    "          # linearly decay the eps value\n",
    "            if steps > DELAY_TRAINING:\n",
    "                eps = MAX_EPSILON - ((steps - DELAY_TRAINING) / EPSILON_MIN_ITER) * \\\n",
    "                    (MAX_EPSILON - MIN_EPSILON) if steps < EPSILON_MIN_ITER else \\\n",
    "                  MIN_EPSILON\n",
    "            steps += 1\n",
    "\n",
    "            if done:\n",
    "                ep_sec_time = int((current_milli_time()-ep_time) / 1000)\n",
    "\n",
    "                if steps > DELAY_TRAINING:\n",
    "                    avg_loss /= cnt\n",
    "                    print(f\"Episode: {i}, Reward: {tot_reward}, avg loss: {avg_loss:.5f}, eps: {eps:.3f}, Time: {ep_sec_time: d}\")\n",
    "                    #tensorboard output\n",
    "                    with train_writer.as_default():\n",
    "                        tf.summary.scalar('reward', tot_reward, step=i)\n",
    "                        tf.summary.scalar('avg loss', avg_loss, step=i)\n",
    "                else:\n",
    "                    print(f\"Pre-training...Episode: {i}\")\n",
    "                if i % GIF_RECORDING_FREQ == 0:\n",
    "                    record_gif(frame_list, i)\n",
    "                ep_time = current_milli_time()\n",
    "                break\n",
    "\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Actual run in \"SpaceInvaders-v0\" environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to source code: \\\n",
    "https://adventuresinmachinelearning.com/atari-space-invaders-dueling-q/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPuGvOo6Dhqg"
   },
   "source": [
    "## Creating the copy section to apply transfer learning on other environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "COJvdicFJc8H",
    "outputId": "a3530e7c-6291-4df4-90a9-19be12247d3c"
   },
   "source": [
    "This part it's still work in progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "IY-QJKHgM4ki",
    "outputId": "5c2b3bb1-993c-4f64-80e7-1b04f4a8fd66"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "1WdJkIpNRQgn",
    "outputId": "9ce0c09b-6d6a-436f-c494-9cb470b6e08f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "d6V_28PUERGA",
    "outputId": "8df7026a-29ea-4c9a-8c0a-4f025b0ae61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fe3109dfad02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprimary_net_breakout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprymary_net_breakout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprimary_net_breakout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prymary_net_breakout' is not defined"
     ]
    }
   ],
   "source": [
    "# Possible way after saving keras model for primary network\n",
    "primary_net_breakout = keras.models.load_model(\"SpaceInv_tnet\")\n",
    "primary_net_breakout.layers.pop()\n",
    "\n",
    "env = gym.make(\"Breakout-v0\")\n",
    "num_actions = env.action_space.n\n",
    "space_dim   = env.observation_space.shape #the image input is resized as before\n",
    "\n",
    "for layer in primary_net_breakout.layers:\n",
    "    layer.trainable = False\n",
    "prymary_net_breakout.add(Dense(num_actions))\n",
    "primary_net_breakout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-PSuu0aM4ry"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "colab_type": "code",
    "id": "QLhGMPPvM4pI",
    "outputId": "6cb95760-a45f-4b76-8951-770808cb30b4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmE9htbhOk8Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "spaceinv_v0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
